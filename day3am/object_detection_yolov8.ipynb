{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwEwxg_CODIC"
      },
      "source": [
        "# Custom Training with YOLOv8\n",
        "\n",
        "In this lab exercise, we will learn to train a custom YOLOv8 model to perform object detection. To do so we will take the following steps:\n",
        "\n",
        "* Gather a dataset of images and label our dataset\n",
        "* Export our dataset to YOLOv8 format\n",
        "* Train YOLOv8 to recognize the objects in our dataset\n",
        "* Evaluate our YOLOv8 model's performance\n",
        "* Run inference to test our deployed model\n",
        "\n",
        "\n",
        "\n",
        "![](https://uploads-ssl.webflow.com/5f6bc60e665f54545a1e52a5/615627e5824c9c6195abfda9_computer-vision-cycle.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfBX5CjAPFtK"
      },
      "source": [
        "# Step 1: Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGBvA5a_10OZ"
      },
      "outputs": [],
      "source": [
        "!pip install -q ultralytics\n",
        "!pip install -q roboflow\n",
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b83Y7TSXO_Y3"
      },
      "source": [
        "# Step 2: Dataset\n",
        "\n",
        "In this exercise, we will use an existing annotated dataset for our training. This dataset, the apples dataset is available from [Roboflow Universe](https://universe.roboflow.com/) which is a collection of open source computer vision datasets.\n",
        "\n",
        "You can read more about the apples dataset [here](https://universe.roboflow.com/roboflow-100/apples-fvpl5). The dataset consists of both normal apple, and damaged apple.\n",
        "\n",
        "We can use Roboflow to also convert the dataset format, if the dataset is not already in YOLOv8 format. Roboflow supports many different [annotation formats](https://roboflow.com/formats)\n",
        "\n",
        "You can also use Roboflow to annotate your own images if they are not already annotated.\n",
        "\n",
        "**Annotation using Roboflow**\n",
        "\n",
        "![](https://roboflow-darknet.s3.us-east-2.amazonaws.com/roboflow-annotate.gif)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LexPNwd2TefQ"
      },
      "source": [
        "To download the dataset from Roboflow, you will need a Roboflow account. You can register for a free account [here](https://app.roboflow.com/login).\n",
        "\n",
        "You can then get your API key from the account you created. Go to **Account -> Settings -> New Workspace -> Roboflow API**.  You should be able to see your API key there. Click on the copy button for Private API Key.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/nyp-sit/nypi/main/resources/roboflow_api_key.png\" width=500/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVnbmLcf2BXD"
      },
      "outputs": [],
      "source": [
        "from roboflow import Roboflow\n",
        "\n",
        "# rf = Roboflow(api_key=\"?????\")\n",
        "\n",
        "rf = Roboflow(api_key=\"cBYcnpRQaCFSCkiX1Y7R\")\n",
        "project = rf.workspace(\"roboflow-100\").project(\"apples-fvpl5\")\n",
        "dataset = project.version(2).download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4rb8Hm1W6u_"
      },
      "source": [
        "By default, ultralytics training script expects your dataset to be in the *datasets* folder. So we will move the downloaded dataset to the *datasets* subfolder, and we also need to change directory in the *datasets* folder to start the train script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gmlV0ub3XwPg"
      },
      "outputs": [],
      "source": [
        "%mkdir datasets\n",
        "%mv apples-2 datasets\n",
        "%cd datasets\n",
        "!yolo detect train data=apples-2/data.yaml model=yolov8n.pt epochs=15\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQZh2iwaZ2pr"
      },
      "source": [
        "# Visualize Training loss and Performance metrics\n",
        "\n",
        "Training losses and performance metrics are saved as Tensorboard logging events.  You can view the metrics using the tensorboard plugin by running the cell below.\n",
        "\n",
        "If you are new to these metrics, the one you want to focus on is `mAP_0.5` - learn more about mean average precision [here](https://blog.roboflow.com/mean-average-precision/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-8KpI4hZUcV"
      },
      "outputs": [],
      "source": [
        "# Start tensorboard\n",
        "# Launch after you have started training\n",
        "# logs save in the folder \"datasets/runs/\"\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir datasets/runs/detect/train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI9J71hVtu_7"
      },
      "source": [
        "# Run validation\n",
        "\n",
        "The following codes run the model against the validation dataset and display the validation results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PojtBMzhi7z"
      },
      "outputs": [],
      "source": [
        "%cd datasets\n",
        "!yolo val model=/content/datasets/runs/detect/train/weights/best.pt data=apples-2/data.yaml\n",
        "%cd ../"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uu5Cjwmabj5"
      },
      "source": [
        "# Running inference on Test Image\n",
        "\n",
        "Now that our model is trained. We can do inference using our best model checkpoint which is located at `datasets/runs/detect/train/weights/best.pt`\n",
        "\n",
        "The results contains the numpy array of the image with detection boxes. channel of the returned image array is in the format of BGR (blue, green, red). If you want to render it using PIL or matplotlib, you need to convert it to RGB format first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUpdYSOZEQwh"
      },
      "outputs": [],
      "source": [
        "# Let's define a function to do the prediction\n",
        "from PIL import Image\n",
        "from ultralytics import YOLO\n",
        "\n",
        "def predict(img):\n",
        "    '''\n",
        "    Parameters\n",
        "    ----------\n",
        "    img: a PIL Image\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    PIL image with bounding boxes\n",
        "    '''\n",
        "\n",
        "\n",
        "    model = YOLO('datasets/runs/detect/train/weights/best.pt')\n",
        "    results = model.predict(source=img, save=True, conf=0.4)\n",
        "    img_bgr = results[0].plot(conf=True, font_size=10)\n",
        "    img_rgb = img_bgr[:, :, [2, 1, 0]]\n",
        "    image_detected = Image.fromarray(img_rgb)\n",
        "\n",
        "    return image_detected\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRc5-ytKpdNt"
      },
      "outputs": [],
      "source": [
        "test_image = '/content/datasets/apples-2/test/images/apple--179-_jpg.rf.a70c7896db8bfdb74e35d9aed5049f54.jpg'\n",
        "test_image = Image.open(test_image)\n",
        "image_detected = predict(test_image)\n",
        "image_detected.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVnEUBzIp_p3"
      },
      "source": [
        "# Demo App\n",
        "\n",
        "Now let's build a demo app that allows us to upload a picture of apple, and it will return the image with bounding boxes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiO1q13-7oGJ"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "gr.Interface(fn=predict,\n",
        "             inputs=gr.Image(type=\"pil\"),\n",
        "             outputs=gr.Image(type=\"pil\")\n",
        "             ).launch(share=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTEMUG4XtPNa"
      },
      "source": [
        "# Exercise\n",
        "\n",
        "You will be given a new dataset that has not been annotated. You will use Roboflow to annotate the images and download the dataset in YOLOv8 format. You can then train a new model as before."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}