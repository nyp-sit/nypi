{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlcN8ctTgVbP"
      },
      "source": [
        "# Supervised Learning- Classification\n",
        "## Classification\n",
        "One of the very famous classification problems in Machine Learning is the IRIS Flower classification problem.  We want to predict the class of Iris given the Sepal, Petal lengths and widths.  The data we will use are in a file called Iris_Data.csv found in\n",
        "\n",
        "https://raw.githubusercontent.com/nyp-sit/data/master/Iris_Data.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzNmjWJsib_P"
      },
      "source": [
        "## Basic Data Analysis\n",
        "Q1. Let's load the data from the url and perform basic data analysis.\n",
        "\n",
        "\n",
        "*   Check the sample size\n",
        "*   Check for the features\n",
        "*   Check if there is any missing values\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uv7Vy3S9eHQh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "url = 'https://raw.githubusercontent.com/nyp-sit/data/master/Iris_Data.csv'\n",
        "df = pd.read_csv(url)\n",
        "print(df.head())\n",
        "print('>>> Check the sample size:')\n",
        "print(df.shape)\n",
        "print('>>> Check for the features: ')\n",
        "print(df.describe())\n",
        "print('>>> Check for missing values')\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqr_VDvSpo-f"
      },
      "source": [
        "\n",
        "Let us first understand the datasets.  It consists of:\n",
        "*   150 rows of data\n",
        "*   The 3 **labels** are Iris-virginica, Iris-setosa and Iris-versicolor\n",
        "*   The 4 **features** are Sepal length, Sepal width, Petal length, Petal width in cm\n",
        "*   There is no missing values\n",
        "\n",
        "This is a **multi-class classification** problem, as there are more than 2 classes to be predicted.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQDmiV0HQUsu"
      },
      "source": [
        "## Exploratory Data Analysis\n",
        "\n",
        "Q2. Let's perform a univariate analysis on the data with\n",
        "\n",
        "*   a count plot to show the counts of each category of Iris species.\n",
        "*   histograms to show the distribution of the 4 features, petal_width, petal_length, sepal_,length, sepal_width\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGb-mIkIdvpW"
      },
      "outputs": [],
      "source": [
        "# count plot using matplotlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df['species'].value_counts().plot(kind='bar')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XT3nWE5Wd93s"
      },
      "outputs": [],
      "source": [
        "# count plot using seaborn\n",
        "\n",
        "import seaborn as sns\n",
        "ax = sns.countplot(x='species', data=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_85yFmdf53-"
      },
      "outputs": [],
      "source": [
        "# Histogram to show distribution of features\n",
        "df.hist()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5uVM5_Oh5ad"
      },
      "outputs": [],
      "source": [
        "# Histrogram with density plot (kde) using seaborn\n",
        "\n",
        "sns.distplot(df['sepal_length'], kde=True)\n",
        "plt.show()\n",
        "sns.distplot(df['sepal_width'], kde=True)\n",
        "plt.show()\n",
        "sns.distplot(df['petal_length'], kde=True)\n",
        "plt.show()\n",
        "sns.distplot(df['petal_width'], kde=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj9lIQt3hg6I"
      },
      "source": [
        "Q3. Let's perform multivariate analysis on the data with\n",
        "\n",
        "*  Scatter matrix\n",
        "*  Box plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBY-UPYhdW24"
      },
      "outputs": [],
      "source": [
        "from pandas.plotting import scatter_matrix\n",
        "scatter_matrix(df)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BttxFDTPTta7"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(df, hue='species')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eV5vCSQfOgua"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x='species', y='sepal_length', data=df)\n",
        "plt.show()\n",
        "sns.boxplot(x='species', y='sepal_width', data=df)\n",
        "plt.show()\n",
        "sns.boxplot(x='species', y='petal_length', data=df)\n",
        "plt.show()\n",
        "sns.boxplot(x='species', y='petal_width', data=df)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjScFWUD6bk2"
      },
      "source": [
        "## Data Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1beHksTEggj"
      },
      "source": [
        "Q4. IRIS class prediction is a multiclass classification problem where target variable has three classes.  The goal is to construct a function which will correctly predict the class to which the new point belongs.\n",
        "\n",
        "We are going to need some data validate the accurary of our model.  We will split the loaded dataset into two, 80% of which we will use to train our models and 20% that we will use to validate our model.\n",
        "\n",
        "*  Create a validation test set using the [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5utLovVDGzCW"
      },
      "outputs": [],
      "source": [
        "# Create a validation test set by splitting the data into 80/20\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(df, test_size = 0.2, random_state=7)\n",
        "\n",
        "X = train.values[:,0:4]\n",
        "Y = train.values[:,4]\n",
        "x_test = test.values[:,0:4]\n",
        "y_test = test.values[:,4]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CfZhuTIxNMv"
      },
      "source": [
        "Q5.  Proceed to train the data using Logistic Regression and K Nearest Neighbours.  Compute the accuracy score and confusion matrix for both algorithm.\n",
        "\n",
        "[Accuracy Score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
        "\n",
        "[Confusion Matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)\n",
        "\n",
        "[Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
        "\n",
        "[Nearest Neighbours](https://scikit-learn.org/stable/modules/neighbors.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sZt8gZh2TaD"
      },
      "outputs": [],
      "source": [
        "from sklearn import linear_model, neighbors\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "classifier = linear_model.LogisticRegression(solver='liblinear', multi_class='ovr')\n",
        "classifier.fit(X,Y)\n",
        "predictions=classifier.predict(x_test)\n",
        "print(accuracy_score(y_test, predictions))\n",
        "print(confusion_matrix(y_test, predictions))\n",
        "\n",
        "classifier = neighbors.KNeighborsClassifier()\n",
        "classifier.fit(X,Y)\n",
        "predictions=classifier.predict(x_test)\n",
        "print(accuracy_score(y_test, predictions))\n",
        "print(confusion_matrix(y_test, predictions))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QY0fRyk6TOXv"
      },
      "source": [
        "Q6. Use K-fold cross-validation technique to randomly splits the training set into 10 distinct subsets to train and evaluate the Logistic Regression and KNN models 10 times and compare their results.\n",
        "[Cross Validation](https://scikit-learn.org/stable/modules/cross_validation.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Nb8-1kX43Wd"
      },
      "outputs": [],
      "source": [
        "from sklearn import model_selection\n",
        "\n",
        "models = {}\n",
        "models['LR'] = linear_model.LogisticRegression(solver='liblinear', multi_class='ovr')\n",
        "models['KNN'] = neighbors.KNeighborsClassifier()\n",
        "\n",
        "results = []\n",
        "names = []\n",
        "score = 'accuracy'\n",
        "\n",
        "for name in models:\n",
        "  model = models.get(name)\n",
        "  kfold = model_selection.KFold(n_splits=10)\n",
        "  cv_results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=score)\n",
        "  results.append(cv_results)\n",
        "  names.append(name)\n",
        "\n",
        "  print('{}: {} ({})'.format(name, cv_results.mean(), cv_results.std()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJTPvoH7LSKX"
      },
      "source": [
        "How to apply decision tree and SVM?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnTejVcILSKY"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "from sklearn import model_selection\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "models = {}\n",
        "models['LR'] = linear_model.LogisticRegression(solver='liblinear', multi_class='ovr')\n",
        "models['KNN'] = neighbors.KNeighborsClassifier()\n",
        "models['DT'] = DecisionTreeClassifier()\n",
        "models['SVM'] = SVC(gamma='auto')\n",
        "\n",
        "results = []\n",
        "names = []\n",
        "score = 'accuracy'\n",
        "\n",
        "for name in models:\n",
        "  model = models.get(name)\n",
        "  kfold = model_selection.KFold(n_splits=10)\n",
        "  cv_results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=score)\n",
        "  results.append(cv_results)\n",
        "  names.append(name)\n",
        "\n",
        "  print('{}: {} ({})'.format(name, cv_results.mean(), cv_results.std()))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}